{"id":"clip-tokenizer-rs-4xo","title":"Create build.rs for napi","description":"Create build.rs file for napi-rs build process.\n\n**Content:**\n```rust\nextern crate napi_build;\n\nfn main() {\n    napi_build::setup();\n}\n```\n\n**Purpose:**\n- Sets up napi-rs build configuration\n- Required for generating the .node native module\n- Handles platform-specific build flags","status":"closed","priority":2,"issue_type":"task","owner":"nathan@ditto.ai","created_at":"2026-01-17T22:40:42.13248572-08:00","created_by":"Nathan Standiford","updated_at":"2026-01-17T22:56:45.306274896-08:00","closed_at":"2026-01-17T22:56:45.306274896-08:00","close_reason":"Closed","dependencies":[{"issue_id":"clip-tokenizer-rs-4xo","depends_on_id":"clip-tokenizer-rs-x5j","type":"blocks","created_at":"2026-01-17T22:41:05.495010888-08:00","created_by":"Nathan Standiford"}]}
{"id":"clip-tokenizer-rs-akc","title":"Update package.json with napi config","description":"Configure package.json for napi-rs native module.\n\n**Key fields:**\n- `name`: \"clip-tokenizer-rs\"\n- `type`: \"module\" (ESM)\n- `main`: \"index.js\" (generated loader)\n- `types`: \"index.d.ts\"\n\n**napi config:**\n```json\n\"napi\": {\n  \"name\": \"clip_tokenizer\",\n  \"triples\": {\n    \"defaults\": false,\n    \"additional\": [\n      \"x86_64-apple-darwin\",\n      \"aarch64-apple-darwin\",\n      \"x86_64-unknown-linux-gnu\",\n      \"aarch64-unknown-linux-gnu\"\n    ]\n  }\n}\n```\n\n**Scripts:**\n- `build`: \"napi build --release --platform --strip\"\n- `build:debug`: \"napi build\"\n- `test`: \"bun test\"\n\n**files array:** index.js, index.d.ts, *.node","status":"closed","priority":2,"issue_type":"task","owner":"nathan@ditto.ai","created_at":"2026-01-17T22:40:42.46373201-08:00","created_by":"Nathan Standiford","updated_at":"2026-01-17T22:56:45.30765838-08:00","closed_at":"2026-01-17T22:56:45.30765838-08:00","close_reason":"Closed","dependencies":[{"issue_id":"clip-tokenizer-rs-akc","depends_on_id":"clip-tokenizer-rs-x5j","type":"blocks","created_at":"2026-01-17T22:41:05.859661657-08:00","created_by":"Nathan Standiford"}]}
{"id":"clip-tokenizer-rs-buw","title":"Update .gitignore","description":"Configure .gitignore for Rust + Node native module project.\n\n**Entries to add:**\n```\n*.node\ntarget/\nnode_modules/\n```\n\n**Important:** Do NOT ignore vocab/ - the vocab file is bundled in the repo.\n\n**Existing entries to keep:**\n- Any existing .gitignore content","status":"closed","priority":3,"issue_type":"task","owner":"nathan@ditto.ai","created_at":"2026-01-17T22:40:43.094372267-08:00","created_by":"Nathan Standiford","updated_at":"2026-01-17T22:45:00.988233574-08:00","closed_at":"2026-01-17T22:45:00.988233574-08:00","close_reason":"Closed"}
{"id":"clip-tokenizer-rs-dhf","title":"Build and verify native module","description":"Build the native module and run tests.\n\n**Build steps:**\n```bash\nbun install\nbun run build\nbun test\n```\n\n**Verification checklist:**\n- [ ] Vocab file exists (~320KB)\n- [ ] Build completes without errors\n- [ ] .node file generated for current platform\n- [ ] All tests pass\n- [ ] Manual test works:\n  ```typescript\n  import { encode, count } from \"./index\";\n  console.log(encode(\"a photo of a cat\")); // [320, 1125, 539, 320, 2368]\n  console.log(count(\"a photo of a cat\")); // 5\n  ```\n\n**Troubleshooting:**\n- If Rust not installed: `curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh`\n- If build fails on instant-clip-tokenizer: check vocab file path","status":"closed","priority":3,"issue_type":"task","owner":"nathan@ditto.ai","created_at":"2026-01-17T22:40:43.722389405-08:00","created_by":"Nathan Standiford","updated_at":"2026-01-17T23:25:49.316957069-08:00","closed_at":"2026-01-17T23:25:49.316957069-08:00","close_reason":"Closed","dependencies":[{"issue_id":"clip-tokenizer-rs-dhf","depends_on_id":"clip-tokenizer-rs-tr5","type":"blocks","created_at":"2026-01-17T22:41:06.804729343-08:00","created_by":"Nathan Standiford"},{"issue_id":"clip-tokenizer-rs-dhf","depends_on_id":"clip-tokenizer-rs-4xo","type":"blocks","created_at":"2026-01-17T22:41:07.116736115-08:00","created_by":"Nathan Standiford"},{"issue_id":"clip-tokenizer-rs-dhf","depends_on_id":"clip-tokenizer-rs-akc","type":"blocks","created_at":"2026-01-17T22:41:07.4318981-08:00","created_by":"Nathan Standiford"},{"issue_id":"clip-tokenizer-rs-dhf","depends_on_id":"clip-tokenizer-rs-buw","type":"blocks","created_at":"2026-01-17T22:41:07.748563063-08:00","created_by":"Nathan Standiford"}]}
{"id":"clip-tokenizer-rs-lxx","title":"Download CLIP vocab file","description":"Download bpe_simple_vocab_16e6.txt.gz from OpenAI's CLIP repo.\n\n**Context:**\n- URL: https://raw.githubusercontent.com/openai/CLIP/main/clip/bpe_simple_vocab_16e6.txt.gz\n- Destination: vocab/bpe_simple_vocab_16e6.txt.gz\n- Size: ~320KB (will be embedded at compile time via include_bytes!)\n- This file contains 49,408 BPE tokens used by CLIP models\n\n**Commands:**\n```bash\nmkdir -p vocab\ncurl -L -o vocab/bpe_simple_vocab_16e6.txt.gz \\\n  https://raw.githubusercontent.com/openai/CLIP/main/clip/bpe_simple_vocab_16e6.txt.gz\n```\n\n**Verification:**\n- File exists and is ~320KB\n- File is gzipped (check with `file vocab/bpe_simple_vocab_16e6.txt.gz`)","status":"closed","priority":1,"issue_type":"task","owner":"nathan@ditto.ai","created_at":"2026-01-17T22:40:36.762425537-08:00","created_by":"Nathan Standiford","updated_at":"2026-01-17T22:45:00.986816948-08:00","closed_at":"2026-01-17T22:45:00.986816948-08:00","close_reason":"Closed"}
{"id":"clip-tokenizer-rs-sw0","title":"Implement Rust tokenizer library","description":"Create src/lib.rs with encode() and count() functions.\n\n**Key implementation details:**\n\n1. **Embed vocab at compile time:**\n   ```rust\n   const VOCAB_GZ: \u0026[u8] = include_bytes!(\"../vocab/bpe_simple_vocab_16e6.txt.gz\");\n   ```\n\n2. **Lazy init with retry support:**\n   Use `OnceLock\u003cMutex\u003cOption\u003cTokenizer\u003e\u003e\u003e` pattern (not plain OnceLock)\n   - Allows retry if initialization fails\n   - Thread-safe\n\n3. **API functions:**\n   - `encode(text: String) -\u003e Vec\u003cu32\u003e` - tokenize text to token IDs\n   - `count(text: String) -\u003e u32` - count tokens in text\n\n4. **instant-clip-tokenizer API:**\n   - `Tokenizer::with_vocabulary(reader, 49408)` - load from gzipped vocab\n   - `tokenizer.encode(\u0026text, \u0026mut tokens)` - encode to Token vec\n   - `Token::to_u16()` - get token ID\n\n**Error handling:**\n- Return napi::Error with GenericFailure status\n- Include descriptive error messages","status":"closed","priority":2,"issue_type":"task","owner":"nathan@ditto.ai","created_at":"2026-01-17T22:40:41.767963338-08:00","created_by":"Nathan Standiford","updated_at":"2026-01-17T23:01:55.23028352-08:00","closed_at":"2026-01-17T23:01:55.23028352-08:00","close_reason":"Closed","dependencies":[{"issue_id":"clip-tokenizer-rs-sw0","depends_on_id":"clip-tokenizer-rs-lxx","type":"blocks","created_at":"2026-01-17T22:41:04.806762519-08:00","created_by":"Nathan Standiford"},{"issue_id":"clip-tokenizer-rs-sw0","depends_on_id":"clip-tokenizer-rs-v9f","type":"blocks","created_at":"2026-01-17T22:41:05.174538945-08:00","created_by":"Nathan Standiford"}]}
{"id":"clip-tokenizer-rs-sxf","title":"Create TypeScript definitions","description":"Create index.d.ts with type declarations.\n\n**Exports:**\n```typescript\n/** Tokenize text to CLIP token IDs */\nexport function encode(text: string): number[];\n\n/** Count the number of CLIP tokens in text */\nexport function count(text: string): number;\n```\n\n**Notes:**\n- Return type is number[] (not Uint32Array) for JS compatibility\n- Functions may throw on initialization failure","status":"closed","priority":3,"issue_type":"task","owner":"nathan@ditto.ai","created_at":"2026-01-17T22:40:42.780342093-08:00","created_by":"Nathan Standiford","updated_at":"2026-01-17T23:02:26.637197164-08:00","closed_at":"2026-01-17T23:02:26.637197164-08:00","close_reason":"Closed","dependencies":[{"issue_id":"clip-tokenizer-rs-sxf","depends_on_id":"clip-tokenizer-rs-sw0","type":"blocks","created_at":"2026-01-17T22:41:06.174833441-08:00","created_by":"Nathan Standiford"}]}
{"id":"clip-tokenizer-rs-tr5","title":"Create test suite","description":"Create index.test.ts with Bun tests.\n\n**Test cases:**\n1. `encode returns token array` - verify returns array with length \u003e 0\n2. `count returns token count` - verify returns number \u003e 0\n3. `encode and count match` - verify encode().length === count()\n4. `handles empty string` - verify empty input returns empty/0\n5. `handles unicode` - verify accented characters work (café, naïve, résumé)\n\n**Framework:** bun:test\n```typescript\nimport { test, expect } from \"bun:test\";\nimport { encode, count } from \"./index\";\n```\n\n**Expected token values (for reference):**\n- \"a photo of a cat\" → [320, 1125, 539, 320, 2368] (5 tokens)","status":"closed","priority":3,"issue_type":"task","owner":"nathan@ditto.ai","created_at":"2026-01-17T22:40:43.414288235-08:00","created_by":"Nathan Standiford","updated_at":"2026-01-17T23:19:22.364143137-08:00","closed_at":"2026-01-17T23:19:22.364143137-08:00","close_reason":"Closed","dependencies":[{"issue_id":"clip-tokenizer-rs-tr5","depends_on_id":"clip-tokenizer-rs-sxf","type":"blocks","created_at":"2026-01-17T22:41:06.489482829-08:00","created_by":"Nathan Standiford"}]}
{"id":"clip-tokenizer-rs-v9f","title":"Configure Cargo.toml dependencies","description":"Set up Rust dependencies for CLIP tokenization.\n\n**Dependencies needed:**\n- `napi = { version = \"2\", features = [\"napi4\"] }` - Node API bindings\n- `napi-derive = \"2\"` - Procedural macros for napi\n- `instant-clip-tokenizer = \"0.1\"` - CLIP tokenizer (70x faster than Python)\n- `flate2 = \"1.0\"` - Gzip decompression for vocab file\n\n**Build dependencies:**\n- `napi-build = \"2\"`\n\n**Cargo.toml structure:**\n```toml\n[package]\nname = \"clip-tokenizer-rs\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[lib]\ncrate-type = [\"cdylib\"]\n```","status":"closed","priority":2,"issue_type":"task","owner":"nathan@ditto.ai","created_at":"2026-01-17T22:40:41.332466703-08:00","created_by":"Nathan Standiford","updated_at":"2026-01-17T22:56:45.304754256-08:00","closed_at":"2026-01-17T22:56:45.304754256-08:00","close_reason":"Closed","dependencies":[{"issue_id":"clip-tokenizer-rs-v9f","depends_on_id":"clip-tokenizer-rs-x5j","type":"blocks","created_at":"2026-01-17T22:41:04.468442018-08:00","created_by":"Nathan Standiford"}]}
{"id":"clip-tokenizer-rs-x5j","title":"Initialize napi-rs project","description":"Set up napi-rs scaffolding for Bun native module.\n\n**Context:**\n- napi-rs provides Rust to Node/Bun native bindings\n- Need to configure for 4 platforms: darwin-x64, darwin-arm64, linux-x64-gnu, linux-arm64-gnu\n- This generates Cargo.toml, build.rs, and package.json scaffolding\n\n**Commands:**\n```bash\nbun add -D @napi-rs/cli\nbunx napi new --path .\n```\n\n**Platform triples to select:**\n- x86_64-apple-darwin\n- aarch64-apple-darwin\n- x86_64-unknown-linux-gnu\n- aarch64-unknown-linux-gnu\n\n**Note:** Will need to modify generated files in subsequent tasks.","status":"closed","priority":1,"issue_type":"task","owner":"nathan@ditto.ai","created_at":"2026-01-17T22:40:38.986491251-08:00","created_by":"Nathan Standiford","updated_at":"2026-01-17T22:54:09.389046176-08:00","closed_at":"2026-01-17T22:54:09.389046176-08:00","close_reason":"napi-rs already initialized in native/ folder"}
